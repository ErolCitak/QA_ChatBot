# QA_BOT_RAG_LANGCHAIN

A modular and efficient Retrieval-Augmented Generation (RAG) system with document upload, vector search, and question answering UI powered by Gradio and LangChain.

---

## ðŸš€ Project Overview

This project allows users to:
- Upload PDF documents.
- Automatically parse and split documents into semantic chunks.
- Create a FAISS-based vector database using sentence-transformer embeddings.
- Ask questions through a Gradio-based UI.
- Get answers generated by a lightweight LLM (e.g., Gemma-2B-IT) via LangChain retrieval pipeline.

The system is fully modular with components for document loading, embedding generation, vector storage, retrieval, and LLM-based answer generation.

---

## ðŸ–¼ Project Architecture


```bash
QA_BOT_RAG_LANGCHAIN/
â”‚
â”œâ”€â”€ chain/                  # LangChain RAG chain builder
â”‚   â””â”€â”€ rag_chain.py
â”‚
â”œâ”€â”€ data/                   # PDF and question datasets
â”‚
â”œâ”€â”€ db/                     # Saved vector databases (FAISS)
â”‚
â”œâ”€â”€ embedding/              # Embedder logic (Sentence Transformers, vectorization)
â”‚   â””â”€â”€ embedder.py
â”‚
â”œâ”€â”€ llm/                    # LLM wrapper logic (HuggingFace Transformers models)
â”‚   â””â”€â”€ llm_wrapper.py
â”‚
â”œâ”€â”€ main.py                 # Gradio App UI
â”œâ”€â”€ main.ipynb              # Optional Notebook version
â”œâ”€â”€ utils.py                # Utility functions (text cleaning etc.)
â”œâ”€â”€ config.py               # Project-wide configurations
â”œâ”€â”€ requirements.txt        # Required libraries
â”œâ”€â”€ README.md               # This file
â””â”€â”€ .gitignore              # Git ignore settings
